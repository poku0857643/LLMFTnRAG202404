{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "XOayE6OPlY0E"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 72515,
     "status": "ok",
     "timestamp": 1720063267048,
     "user": {
      "displayName": "Colin Wu",
      "userId": "13240004443682062348"
     },
     "user_tz": -480
    },
    "id": "EqCuRuVRAvoc",
    "outputId": "9bc2163f-4bfb-4e81-bdad-87b7a7c06d48"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/43.2 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.2/43.2 kB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m314.0/314.0 kB\u001B[0m \u001B[31m10.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m975.5/975.5 kB\u001B[0m \u001B[31m45.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m119.8/119.8 MB\u001B[0m \u001B[31m12.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m227.1/227.1 kB\u001B[0m \u001B[31m25.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m337.4/337.4 kB\u001B[0m \u001B[31m30.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m127.5/127.5 kB\u001B[0m \u001B[31m13.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m141.1/141.1 kB\u001B[0m \u001B[31m18.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.3/21.3 MB\u001B[0m \u001B[31m67.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers einops accelerate langchain bitsandbytes sentence_transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23047,
     "status": "ok",
     "timestamp": 1720063290066,
     "user": {
      "displayName": "Colin Wu",
      "userId": "13240004443682062348"
     },
     "user_tz": -480
    },
    "id": "3wWEue2MA1AT",
    "outputId": "94c1994e-b278-488d-91da-2f6edd31a1fb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m290.4/290.4 kB\u001B[0m \u001B[31m7.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m27.0/27.0 MB\u001B[0m \u001B[31m62.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pypdf\n",
    "!pip install -q python-dotenv\n",
    "!pip install -q joblib\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 31764,
     "status": "ok",
     "timestamp": 1720063321809,
     "user": {
      "displayName": "Colin Wu",
      "userId": "13240004443682062348"
     },
     "user_tz": -480
    },
    "id": "hvlmldCQA1ua",
    "outputId": "6f457ddd-87a0-4c08-bf5a-2f820d232cd5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15.4/15.4 MB\u001B[0m \u001B[31m83.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m78.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m75.6/75.6 kB\u001B[0m \u001B[31m10.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m130.8/130.8 kB\u001B[0m \u001B[31m21.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m328.3/328.3 kB\u001B[0m \u001B[31m43.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m78.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m77.9/77.9 kB\u001B[0m \u001B[31m12.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m9.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.2/49.2 kB\u001B[0m \u001B[31m8.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting langchain-community\n",
      "  Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m39.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.2.11)\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.6)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.83)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.4.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.8.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.23.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (3.0.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.19.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (4.41.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2023.6.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain-community) (0.2.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (2.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.3.0+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.11.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (9.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.12.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.5.82)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Installing collected packages: langchain-huggingface, langchain-community\n",
      "Successfully installed langchain-community-0.2.6 langchain-huggingface-0.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -q llama-index\n",
    "!pip install -q llama-index-llms-huggingface\n",
    "!pip install -q llama-index-embeddings-langchain\n",
    "!pip install langchain-community langchain-core langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 11082,
     "status": "ok",
     "timestamp": 1720063332869,
     "user": {
      "displayName": "Colin Wu",
      "userId": "13240004443682062348"
     },
     "user_tz": -480
    },
    "id": "vQo_gd81A3cs",
    "outputId": "821d5f4b-0e3a-4a69-b367-0e0ecab8da7b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92836,
     "status": "ok",
     "timestamp": 1720063425686,
     "user": {
      "displayName": "Colin Wu",
      "userId": "13240004443682062348"
     },
     "user_tz": -480
    },
    "id": "ddq-yhbcAjRt",
    "outputId": "9e3d7f24-fc05-4b16-c6f1-29da43fedccd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7509,
     "status": "ok",
     "timestamp": 1720063433187,
     "user": {
      "displayName": "Colin Wu",
      "userId": "13240004443682062348"
     },
     "user_tz": -480
    },
    "id": "cqGji8C6BRcT",
    "outputId": "eb3fb6f1-9560-42a2-c803-09aa05bba9d7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
    "from llama_index.core import PromptTemplate, Settings\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "import numpy as np\n",
    "\n",
    "showMessage = True\n",
    "\n",
    "\n",
    "# GPU acceleration with metal on Mac\n",
    "# device = torch.device(\"cuda\")\n",
    "# GPU acceleration with CUDA\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354,
     "referenced_widgets": [
      "d7fbc89549b44ef39f506af0467a9195",
      "f23ce9b8a1054e2db673e52870933663",
      "468dae1185b248cf94667b8dcfdc49b0",
      "308879c2c31c4a7cacde94b5abe01d09",
      "1f4c2f06111343b7994e3729b8f93c0d",
      "f156f5b0ec4d4759ad8f63f6ec798e3b",
      "c195467ad8d7435aadbbb24a2e957c9a",
      "1e8553d4fd6d491e89b16afdbcb48de2",
      "e76431509ff9489d841b5c65e3e157ed",
      "051ac6183a6945d0a1534ad4420f599c",
      "b8435ff659ef402489f8a9f5f54a6b87"
     ]
    },
    "executionInfo": {
     "elapsed": 394684,
     "status": "ok",
     "timestamp": 1720063827862,
     "user": {
      "displayName": "Colin Wu",
      "userId": "13240004443682062348"
     },
     "user_tz": -480
    },
    "id": "KdVjw2hRBhqn",
    "outputId": "302c0996-aefd-4485-ecdb-954b1dd621ce"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /usr/local/lib/python3.10/dist-\n",
      "[nltk_data]     packages/llama_index/legacy/_static/nltk_cache...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /usr/local/lib/python3.10/dist-\n",
      "[nltk_data]     packages/llama_index/legacy/_static/nltk_cache...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2024-07-04 03:24:03] Index loaded from drive/MyDrive/Model/index.pkl\n",
      "[2024-07-04 03:24:11] Embedding model loaded.████████████████████\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7fbc89549b44ef39f506af0467a9195"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2024-07-04 03:30:28] Model and tokenizer loaded.████████████████████\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:llama_index.llms.huggingface.base:The model `StabilityAI/stablelm-tuned-alpha-3b` and tokenizer `drive/MyDrive/Model/llm_tokenizer` are different, please ensure that they are compatible.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2024-07-04 03:30:28] LLM configuration loaded.████████████████████████████████████████\n",
      "[2024-07-04 03:30:28] LLM initialized.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from llama_index.legacy.embeddings.langchain import LangchainEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core import ServiceContext\n",
    "\n",
    "LLM_MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# Function to print the current time and a message\n",
    "def log_time(message):\n",
    "    if showMessage:\n",
    "        print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {message}\")\n",
    "\n",
    "\n",
    "# Load the vector index\n",
    "def load_index(directory_path):\n",
    "    index_file_path = os.path.join(directory_path, \"index.pkl\")\n",
    "\n",
    "    with open(index_file_path, \"rb\") as f:\n",
    "        index = pickle.load(f)\n",
    "\n",
    "    log_time(f\"Index loaded from {index_file_path}\")\n",
    "    return index\n",
    "\n",
    "\n",
    "# Load the model and tokenizer\n",
    "def load_model(directory_path):\n",
    "    model_save_path = os.path.join(directory_path, \"llm_model\")\n",
    "    tokenizer_save_path = os.path.join(directory_path, \"llm_tokenizer\")\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_save_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_save_path)\n",
    "\n",
    "    log_time(\"Model and tokenizer loaded.\" + \"██\" * 10)\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "# Load the embedding model\n",
    "def load_embedding_model(directory_path):\n",
    "    embedding_model_path = os.path.join(directory_path, \"embedding_model_cpu.pkl\")\n",
    "\n",
    "    with open(embedding_model_path, \"rb\") as f:\n",
    "        embed_model = pickle.load(f)\n",
    "        log_time(\"Embedding model loaded.\" + \"██\" * 10)\n",
    "    return embed_model\n",
    "\n",
    "\n",
    "# Load LLM configuration from JSON file\n",
    "def load_config(directory_path):\n",
    "    config_file_path = os.path.join(directory_path, \"llm_config.json\")\n",
    "\n",
    "    with open(config_file_path, \"r\") as f:\n",
    "        llm_config = json.load(f)\n",
    "        log_time(\"LLM configuration loaded.\" + \"██\" * 20)\n",
    "    return llm_config\n",
    "\n",
    "\n",
    "# Import the saved model with HuggingFace\n",
    "def initialize_llm(llm_config, model, tokenizer):\n",
    "    llm = HuggingFaceLLM(\n",
    "        context_window=llm_config[\"context_window\"],\n",
    "        max_new_tokens=llm_config[\"max_new_tokens\"],\n",
    "        generate_kwargs=llm_config[\"generate_kwargs\"],\n",
    "        system_prompt=llm_config[\"system_prompt\"],\n",
    "        query_wrapper_prompt=PromptTemplate(\"<|USER|>{query_str}<|ASSISTANT|>\"),\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        # tokenizer_name=LLM_MODEL_NAME,\n",
    "        # model_name=LLM_MODEL_NAME,\n",
    "        # device_map=\"auto\",\n",
    "\n",
    "    )\n",
    "\n",
    "    log_time(\"LLM initialized.\")\n",
    "    return llm\n",
    "\n",
    "# congfigure the settings\n",
    "def configure_settings(embed_model, llm):\n",
    "    # try:\n",
    "    #     # Initialize HuggingFaceEmbeddings with model name\n",
    "    #     wrapped_embed_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
    "    #     log_time(f\"HuggingFaceEmbeddings initialized with model: {EMBEDDING_MODEL_NAME}\")\n",
    "\n",
    "    #     # Wrap embed_model with LangchainEmbedding\n",
    "    #     embed_model = LangchainEmbedding(EMBEDDING_MODEL_NAME)\n",
    "    #     log_time(\"LangchainEmbedding created.\")\n",
    "    # except Exception as e:\n",
    "    #     log_time(f\"Error during embedding model wrapping: {e}\")\n",
    "    #     raise\n",
    "    Settings.embed_model = embed_model\n",
    "    Settings.llm = llm\n",
    "    Settings.chunk_size = 1024\n",
    "    log_time(\"Settings configured.\")\n",
    "    return Settings.embed_model\n",
    "\n",
    "# embed_model = configure_settings(embed_model, llm)\n",
    "\n",
    "def initialize_all(directory):\n",
    "    index = load_index(directory)\n",
    "    embed_model = load_embedding_model(directory)\n",
    "    model, tokenizer = load_model(directory)\n",
    "    llm_config = load_config(directory)\n",
    "    llm = initialize_llm(llm_config, model, tokenizer)\n",
    "    return model, tokenizer, llm, embed_model, index\n",
    "\n",
    "# Initialize the model, tokenizer, and settings when the module is imported\n",
    "model_dir = \"drive/MyDrive/Model/\"\n",
    "model, tokenizer, llm, embed_model, index = initialize_all(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vwt0dBa59_x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oo_OAyTsBt5A"
   },
   "outputs": [],
   "source": [
    "def generate_response(model, tokenizer, question):\n",
    "    try:\n",
    "        log_time(\"Tokenizing input...\")\n",
    "        inputs = tokenizer(question, return_tensors=\"pt\").to(device)\n",
    "        log_time(\"Input tokenized.\")\n",
    "\n",
    "        log_time(\"Generating response...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # with torch.no_grad():  # Disable gradient calculation for inference\n",
    "              # with torch.cuda.amp.autocast():\n",
    "        output = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=300,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        log_time(f\"Response generated in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        log_time(\"Decoding response...\")\n",
    "        response = tokenizer.decode(output[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "        log_time(\"Response decoded.\")\n",
    "\n",
    "        # Move the model back to CPU to free up GPU memory\n",
    "        # model.to('cpu')\n",
    "        # torch.cuda.empty_cache()\n",
    "\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        log_time(f\"Failed to generate response: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ppwWE5LmuN6o"
   },
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# from llama_index.core import VectorStoreIndex, Document, QueryBundle\n",
    "# import os\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "\n",
    "# # Function to initialize the embedding model\n",
    "# def initialize_embedding_model(model_name):\n",
    "#     embed_model = SentenceTransformer(model_name)\n",
    "#     return embed_model\n",
    "\n",
    "# # Function to embed a query\n",
    "# def embed_query(query, embed_model):\n",
    "#     query_embedding = embed_model.encode(query)\n",
    "#     return query_embedding\n",
    "\n",
    "# # Function to search the vector index\n",
    "# def search_index(query, index, embed_model):\n",
    "#     # Embed the query\n",
    "#     query_embedding = embed_query(query, embed_model)\n",
    "\n",
    "#     # Create a QueryBundle object\n",
    "#     query_bundle = QueryBundle(query_str=query, query_embedding=query_embedding.tolist())\n",
    "\n",
    "#     # Use the `as_retriever` method to create a retriever engine\n",
    "#     retriever = index.as_retriever()\n",
    "\n",
    "#     print(query_embedding)\n",
    "\n",
    "#     print(\"██\"*20)\n",
    "#     print(query_bundle)\n",
    "\n",
    "#     print(\"██\"*20)\n",
    "#     print(retriever)\n",
    "\n",
    "\n",
    "\n",
    "#     # Retrieve all documents based on the query bundle\n",
    "#     response = retriever.retrieve(query_bundle)\n",
    "\n",
    "#     # Limit the number of documents processed\n",
    "#     top_k = 5  # Adjust as needed\n",
    "#     response = response[:top_k]\n",
    "\n",
    "#     # Extract the texts from the retrieved documents\n",
    "#     top_k_docs = [doc.text for doc in response]\n",
    "\n",
    "#     return top_k_docs\n",
    "\n",
    "# # Function to generate a response using the LLM\n",
    "# def generate_response(query, top_k_docs, llm):\n",
    "#     context = \" \".join(top_k_docs)\n",
    "#     input_text = f\"Context: {context}\\n\\nQuery: {query}\"\n",
    "#     response = llm.generate(input_text)\n",
    "#     return response\n",
    "\n",
    "# # Function to handle a query\n",
    "# def handle_query(query, model_name, index, llm):\n",
    "#     embed_model = initialize_embedding_model(model_name)\n",
    "#     top_k_docs = search_index(query, index, embed_model)  # Pass the embedding model\n",
    "#     response = generate_response(query, top_k_docs, llm)\n",
    "#     return response\n",
    "\n",
    "# # Load the vector index\n",
    "# with open('drive/MyDrive/Model/index.pkl', 'rb') as f:\n",
    "#     index = pickle.load(f)\n",
    "\n",
    "# # Example usage\n",
    "# model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "# query = \"What are the benefits of using ECG to measure your heart?\"\n",
    "# response = handle_query(query, model_name, index, llm)\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6A-3b_DEgrh"
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(llm=llm, similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "executionInfo": {
     "elapsed": 8329,
     "status": "error",
     "timestamp": 1719470398368,
     "user": {
      "displayName": "Colin Wu",
      "userId": "13240004443682062348"
     },
     "user_tz": -480
    },
    "id": "kxCEpSjOuHUB",
    "outputId": "1caeffb8-56e5-4853-f5e1-0cd9ba528164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Enter your question: What is ECG?\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LangchainEmbedding' object has no attribute '_langchain_embedding'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-27-f1de836e3f2f>\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m   \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"*\"\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;36m30\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m   \u001B[0mquestion\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Enter your question: \"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m   \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mquery_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquestion\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m   \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m   \u001B[0mdone\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"End the chat? (y/n): \"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"y\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    228\u001B[0m             )\n\u001B[1;32m    229\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSpanDropEvent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspan_id\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mid_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr_str\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/base/base_query_engine.py\u001B[0m in \u001B[0;36mquery\u001B[0;34m(self, str_or_query_bundle)\u001B[0m\n\u001B[1;32m     50\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr_or_query_bundle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m                 \u001B[0mstr_or_query_bundle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mQueryBundle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr_or_query_bundle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 52\u001B[0;31m             \u001B[0mquery_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_query\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr_or_query_bundle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     53\u001B[0m         dispatcher.event(\n\u001B[1;32m     54\u001B[0m             \u001B[0mQueryEndEvent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstr_or_query_bundle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mquery_result\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    228\u001B[0m             )\n\u001B[1;32m    229\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSpanDropEvent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspan_id\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mid_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr_str\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/query_engine/retriever_query_engine.py\u001B[0m in \u001B[0;36m_query\u001B[0;34m(self, query_bundle)\u001B[0m\n\u001B[1;32m    187\u001B[0m             \u001B[0mCBEventType\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mQUERY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpayload\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mEventPayload\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mQUERY_STR\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mquery_bundle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquery_str\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    188\u001B[0m         ) as query_event:\n\u001B[0;32m--> 189\u001B[0;31m             \u001B[0mnodes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery_bundle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    190\u001B[0m             response = self._response_synthesizer.synthesize(\n\u001B[1;32m    191\u001B[0m                 \u001B[0mquery\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mquery_bundle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/query_engine/retriever_query_engine.py\u001B[0m in \u001B[0;36mretrieve\u001B[0;34m(self, query_bundle)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mretrieve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquery_bundle\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mQueryBundle\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mNodeWithScore\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 144\u001B[0;31m         \u001B[0mnodes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_retriever\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery_bundle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    145\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply_node_postprocessors\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnodes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquery_bundle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mquery_bundle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    228\u001B[0m             )\n\u001B[1;32m    229\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSpanDropEvent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspan_id\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mid_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr_str\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/base/base_retriever.py\u001B[0m in \u001B[0;36mretrieve\u001B[0;34m(self, str_or_query_bundle)\u001B[0m\n\u001B[1;32m    241\u001B[0m                 \u001B[0mpayload\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mEventPayload\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mQUERY_STR\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mquery_bundle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquery_str\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    242\u001B[0m             ) as retrieve_event:\n\u001B[0;32m--> 243\u001B[0;31m                 \u001B[0mnodes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_retrieve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery_bundle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    244\u001B[0m                 \u001B[0mnodes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle_recursive_retrieval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery_bundle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnodes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    245\u001B[0m                 retrieve_event.on_end(\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    228\u001B[0m             )\n\u001B[1;32m    229\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSpanDropEvent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspan_id\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mid_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr_str\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/indices/vector_store/retrievers/retriever.py\u001B[0m in \u001B[0;36m_retrieve\u001B[0;34m(self, query_bundle)\u001B[0m\n\u001B[1;32m     95\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mquery_bundle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery_bundle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_strs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     96\u001B[0m                 query_bundle.embedding = (\n\u001B[0;32m---> 97\u001B[0;31m                     self._embed_model.get_agg_embedding_from_queries(\n\u001B[0m\u001B[1;32m     98\u001B[0m                         \u001B[0mquery_bundle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_strs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     99\u001B[0m                     )\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/base/embeddings/base.py\u001B[0m in \u001B[0;36mget_agg_embedding_from_queries\u001B[0;34m(self, queries, agg_fn)\u001B[0m\n\u001B[1;32m    182\u001B[0m     ) -> Embedding:\n\u001B[1;32m    183\u001B[0m         \u001B[0;34m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 184\u001B[0;31m         \u001B[0mquery_embeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_query_embedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mquery\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mqueries\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    185\u001B[0m         \u001B[0magg_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0magg_fn\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mmean_agg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0magg_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery_embeddings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/base/embeddings/base.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    182\u001B[0m     ) -> Embedding:\n\u001B[1;32m    183\u001B[0m         \u001B[0;34m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 184\u001B[0;31m         \u001B[0mquery_embeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_query_embedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mquery\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mqueries\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    185\u001B[0m         \u001B[0magg_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0magg_fn\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mmean_agg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0magg_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery_embeddings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    228\u001B[0m             )\n\u001B[1;32m    229\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSpanDropEvent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspan_id\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mid_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr_str\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/base/embeddings/base.py\u001B[0m in \u001B[0;36mget_query_embedding\u001B[0;34m(self, query)\u001B[0m\n\u001B[1;32m    131\u001B[0m             \u001B[0mCBEventType\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEMBEDDING\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpayload\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mEventPayload\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSERIALIZED\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    132\u001B[0m         ) as event:\n\u001B[0;32m--> 133\u001B[0;31m             \u001B[0mquery_embedding\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_query_embedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    134\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m             event.on_end(\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/instrumentation/dispatcher.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(func, instance, args, kwargs)\u001B[0m\n\u001B[1;32m    228\u001B[0m             )\n\u001B[1;32m    229\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSpanDropEvent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspan_id\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mid_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr_str\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/embeddings/langchain/base.py\u001B[0m in \u001B[0;36m_get_query_embedding\u001B[0;34m(self, query)\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_get_query_embedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquery\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m         \u001B[0;34m\"\"\"Get query embedding.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 62\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_langchain_embedding\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membed_query\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     63\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m     \u001B[0;32masync\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_aget_query_embedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquery\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'LangchainEmbedding' object has no attribute '_langchain_embedding'"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "while not done:\n",
    "  print(\"*\"*30)\n",
    "  question = input(\"Enter your question: \")\n",
    "  response = query_engine.query(question)\n",
    "  print(response)\n",
    "  done = input(\"End the chat? (y/n): \") == \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1595579,
     "status": "ok",
     "timestamp": 1719218383846,
     "user": {
      "displayName": "Colin Wu",
      "userId": "13240004443682062348"
     },
     "user_tz": -480
    },
    "id": "w0LQoTbFB7IX",
    "outputId": "a1d1f823-b490-4eb7-d2c4-ed83c1719e5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type \"exit\" to exit\n",
      "Enter your question: What does Revlis Biotech Company Limited do?\n",
      "[2024-06-24 08:13:22] Tokenizing input...\n",
      "[2024-06-24 08:13:22] Input tokenized.\n",
      "[2024-06-24 08:13:22] Generating response...\n",
      "[2024-06-24 08:15:50] Response generated in 148.01 seconds.\n",
      "[2024-06-24 08:15:50] Decoding response...\n",
      "[2024-06-24 08:15:50] Response decoded.\n",
      "\n",
      "\n",
      "Revlis Biotech Company Limited is a biotechnology company that specializes in the research, development, and commercialization of innovative biotech products, including vaccines, diagnostic kits, and pharmaceuticals. The company's mission is to improve human health and quality of life by developing and delivering effective and safe biotech products that address unmet medical needs.\n",
      "\n",
      "Revlis Biotech Company Limited is committed to advancing the field of biotechnology through cutting-edge research and development, and its products are designed to improve the lives of patients around the world. The company's product portfolio includes a range of innovative biotech products, such as:\n",
      "\n",
      "1. Vaccines: Revlis Biotech Company Limited develops and commercializes vaccines that protect against infectious diseases, including viral, bacterial, and fungal infections.\n",
      "2. Diagnostic kits: The company's diagnostic kits are designed to detect and diagnose a range of medical conditions, including infectious diseases, cancer, and genetic disorders.\n",
      "3. Pharmaceuticals: Revlis Biotech Company Limited develops and commercializes pharmaceuticals that treat a range of medical conditions, including cancer, cardiovascular disease, and autoimmune disorders.\n",
      "\n",
      "\n",
      "Type \"exit\" to exit\n",
      "Enter your question: 9hj8*Ufjksa saif9JAFS*@!1092))9\n",
      "[2024-06-24 08:16:59] Tokenizing input...\n",
      "[2024-06-24 08:16:59] Input tokenized.\n",
      "[2024-06-24 08:16:59] Generating response...\n",
      "[2024-06-24 08:19:27] Response generated in 148.69 seconds.\n",
      "[2024-06-24 08:19:27] Decoding response...\n",
      "[2024-06-24 08:19:27] Response decoded.\n",
      "832987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321987654321\n",
      "Type \"exit\" to exit\n",
      "Enter your question: exit\n",
      "exiting...\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  try:\n",
    "    print(\"Type \\\"exit\\\" to exit\")\n",
    "    question = input(\"Enter your question: \")\n",
    "\n",
    "    if question == \"exit\":\n",
    "      print(\"exiting...\")\n",
    "      break\n",
    "    response = generate_response(model, tokenizer, question)\n",
    "\n",
    "    print(response)\n",
    "  except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wh9eOgmD8bba"
   },
   "outputs": [],
   "source": [
    "import os, logging, sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import psutil\n",
    "\n",
    "# Specify the directory containing the papers\n",
    "papers_directory = \"drive/MyDrive/papers/\"\n",
    "\n",
    "# Function to find all PDF files in a directory and its subdirectories\n",
    "def find_all_pdfs(directory):\n",
    "    pdf_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.pdf'):\n",
    "                pdf_files.append(os.path.join(root, file))\n",
    "                # print(f\"Found PDF file: {os.path.join(root, file)}\")\n",
    "    return pdf_files\n",
    "\n",
    "# Get a list of all PDF files in the directory and its subdirectories\n",
    "pdf_files = find_all_pdfs(papers_directory)\n",
    "\n",
    "# Initialize the documents list\n",
    "documents = []\n",
    "\n",
    "# Function to check memory usage\n",
    "def check_memory_usage(threshold=80):\n",
    "    memory = psutil.virtual_memory()\n",
    "    return memory.percent < threshold\n",
    "\n",
    "\n",
    "# Batch size for processing PDF files\n",
    "batch_size = 10\n",
    "\n",
    "# Process PDF files in batches\n",
    "for i in range(0, len(pdf_files), batch_size):\n",
    "    if not check_memory_usage():\n",
    "        logging.warning(\"Memory usage is high, pausing processing.\")\n",
    "        break\n",
    "    batch = pdf_files[i:i+batch_size]\n",
    "    for pdf_file in batch:\n",
    "        try:\n",
    "            reader = SimpleDirectoryReader(input_dir=os.path.dirname(pdf_file), required_exts=\".pdf\").load_data()\n",
    "            documents.extend(reader)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to read {pdf_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBb1lqV1B1WC",
    "collapsed": true,
    "executionInfo": {
     "status": "ok",
     "timestamp": 1720067123266,
     "user_tz": -480,
     "elapsed": 34312,
     "user": {
      "displayName": "Colin Wu",
      "userId": "13240004443682062348"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "74f00283-d539-485e-8f6b-ec96b6b828cf"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "\n",
    "# model_path = os.path.join(directory_path, \"embedding_model_cpu.pkl\")\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "# Extract text from documents\n",
    "texts = [doc.text for doc in documents]\n",
    "\n",
    "\n",
    "# Select 10% of the documents randomly\n",
    "sample_size = int(0.1 * len(texts))\n",
    "sampled_texts = random.sample(texts, sample_size)\n",
    "\n",
    "# Generate embeddings for the texts\n",
    "embeddings = [embeddings_model.embed_query(text) for text in sampled_texts]\n",
    "embeddings_array = np.array(embeddings)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = embeddings_array.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings_array)\n",
    "\n",
    "# Optionally, save the index and responses\n",
    "faiss.write_index(index, 'index_small.faiss')\n",
    "np.save('responses_small.npy', sampled_texts)\n",
    "\n",
    "# Load FAISS index and responses\n",
    "index = faiss.read_index('index_small.faiss')\n",
    "responses = np.load('responses_small.npy', allow_pickle=True)\n",
    "\n",
    "def find_best_response(text):\n",
    "    # Generate embedding for the input text\n",
    "    embedding = np.array(embeddings_model.embed_query(text)).reshape(1, -1)\n",
    "    # print(embedding)\n",
    "\n",
    "    # Query the FAISS index\n",
    "    D, I = index.search(embedding, 1)  # Retrieve top 1 most similar embedding\n",
    "    best_response = responses[I[0][0]]\n",
    "    return best_response\n",
    "\n",
    "# # Example usage\n",
    "# input_text = \"What are the benefits of using ECG to measure your heart?\"\n",
    "# best_response = find_best_response(input_text)\n",
    "# print(best_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Generate answer from context:\n",
    "def generate_response_from_context(model, tokenizer, question, context):\n",
    "    try:\n",
    "        log_time(\"Tokenizing input...\")\n",
    "\n",
    "        input_text = f\"Question: {question}\\nContext: {context}\"\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "        log_time(\"Input tokenized.\")\n",
    "\n",
    "        log_time(\"Generating response...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        output = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=512,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        log_time(f\"Response generated in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        log_time(\"Decoding response...\")\n",
    "        response = tokenizer.decode(output[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "        log_time(\"Response decoded.\")\n",
    "\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        log_time(f\"Failed to generate response: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "# input_text = \"According to the World Health Organization (WHO), noncommunicable diseases (NCDs) kill how many people anually?\"\n",
    "# input_text = \"What are some wearable devices that can be used to detect AFib?\"\n",
    "# input_text = \"If a patient's fasting blood glucose levels are 120 mg/dl, how likely is it that they have diabetes?\"\n",
    "# input_text = \"How are Convolutional Neural Networks used in predicting blood glucose levels?\"\n",
    "# input_text = \"Are you a goated sigma level 9000 rizzler with a skibidi gyatt, or do you pay fanum tax and touch grass?\"\n",
    "# input_text = \"What is mitochondrial dysfunction and how can you prevent it?\"\n",
    "while True:\n",
    "  input_text = input(\"Enter your question or type 'exit' to quit: \")\n",
    "  if input_text == 'exit':\n",
    "      break\n",
    "  print(input_text)\n",
    "  best_context = find_best_response(input_text)\n",
    "  print(\"Context: \" + best_context)\n",
    "  response = generate_response_from_context(model, tokenizer, input_text, best_context)\n",
    "  print(\"Answer: \" + response)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w25IpkNR8lKx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719818206437,
     "user_tz": -480,
     "elapsed": 1494561,
     "user": {
      "displayName": "Colin Wu",
      "userId": "13240004443682062348"
     }
    },
    "outputId": "14c21800-6586-49e4-d20b-00fa83de1c75"
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question or type 'exit' to quit: What are some ways in using Machine Learning would be helpful in detecting heart related diseases? \n",
      "What are some ways in using Machine Learning would be helpful in detecting heart related diseases? \n",
      "Context: Expert Systems With Applications 243 (2024) 122934\n",
      "14J.E. Arco et al.\n",
      "Xiao, R., Xu, Y., Pelter, M., Fidler, R., Badilini, F., Mortara, D., et al. (2018). Monitoring\n",
      "significant ST changes through deep learning. Journal of Electrocardiology ,51,\n",
      "S78–S82.\n",
      "Yamakawa, T., Miyajima, M., Fujiwara, K., Kano, M., Suzuki, Y., Watanabe, Y., et al.\n",
      "(2020a). Wearable epileptic seizure prediction system with machine-learning-based\n",
      "anomaly detection of heart rate variability. Sensors ,20(14).\n",
      "Yamakawa, T., Miyajima, M., Fujiwara, K., Kano, M., Suzuki, Y., Watanabe, Y., et al.\n",
      "(2020b). Wearable epileptic seizure prediction system with machine-learning-based\n",
      "anomaly detection of heart rate variability. Sensors (Basel, Switzerland) ,20.Yang, A. C., Tsai, S.-J., Hong, C.-J., Yang, C.-H., Hsieh, C.-H., & Liu, M.-E. (2008).\n",
      "Association between heart rate variability and cognitive function in elderly\n",
      "community-dwelling men without dementia: A preliminary report. Journal of the\n",
      "American Geriatrics Society ,56, 958–960.\n",
      "Zubrikhina, M., Abramova, O., Yarkin, V., Ushakov, V., Ochneva, A., Bernstein, A., et al.\n",
      "(2023). Machine learning approaches to mild cognitive impairment detection based\n",
      "on structural MRI data and morphometric features. Cognitive Systems Research ,78,\n",
      "87–95.\n",
      "[2024-07-01 06:53:09] Tokenizing input...\n",
      "[2024-07-01 06:53:09] Input tokenized.\n",
      "[2024-07-01 06:53:09] Generating response...\n",
      "[2024-07-01 06:58:00] Response generated in 291.80 seconds.\n",
      "[2024-07-01 06:58:00] Decoding response...\n",
      "[2024-07-01 06:58:00] Response decoded.\n",
      "Answer: \n",
      "Zhang, Y., Liu, X., Li, J., Zhang, J., & Li, X. (2022). Detection of cardiovascular disease\n",
      "using machine learning techniques based on medical images. Journal of Medical\n",
      "Imaging and Health Informatics ,12(5), 788–796.\n",
      "Zheng, J., Zhang, Y., Liu, X., Li, J., Zhang, J., & Li, X. (2022). Detection of cardiovascular\n",
      "disease using machine learning techniques based on medical images. Journal of Medical\n",
      "Imaging and Health Informatics ,12(5), 788–796.\n",
      "Machine learning techniques can be used to detect heart-related diseases in various ways, including:\n",
      "1. Heart rate variability analysis: Machine learning algorithms can be used to analyze heart rate variability (HRV) patterns in patients with heart-related diseases, such as arrhythmias, heart failure, and coronary artery disease. HRV is a measure of the variation in the time interval between heartbeats, and it can be used to detect abnormal heart function.\n",
      "2. Electrocardiogram (ECG) analysis: Machine learning algorithms can be used to analyze ECG signals to detect abnormal heart rhythms, such as atrial fibrillation, ventricular tachycardia, and ventricular fibrillation.\n",
      "3. Imaging analysis: Machine learning algorithms can be used to analyze medical images, such as echocardiograms and magnetic resonance imaging (MRI) scans, to detect heart defects and abnormalities.\n",
      "4. Clinical data analysis: Machine learning algorithms can be used to analyze clinical data, such as patient demographics, medical history, and laboratory results, to identify patterns and predict heart-related diseases.\n",
      "5. Wearable device analysis: Machine learning algorithms can be used to analyze data from wearable devices, such as fitness trackers and smartwatches, to detect abnormal heart rhythms and predict heart-related diseases.\n",
      "6. Predictive modeling: Machine learning algorithms can be used to build predictive models that can forecast the risk of heart-related diseases based on patient data.\n",
      "7.\n",
      "Enter your question or type 'exit' to quit: How do you reduce noise in an ECG signal (improving the signal quality)?\n",
      "How do you reduce noise in an ECG signal (improving the signal quality)?\n",
      "Context:  \n",
      " A New Method to Reduce Motion Artifact in Electrocardiogram  \n",
      "Based on an Innovative Skin -Electrode Impedance Model  \n",
      " \n",
      "Yajian GAN1, Wenceslas RAHAJANDRAIBE1, Remy VAUCHE1, Blaise RAVELO2, Nominoë LORRIERE1 and \n",
      "Rachid BOUCHAKOUR3, \n",
      "1 Aix Marseille Univ, Université de Toulon, CNRS, IM2NP, Marseille, France  \n",
      "2 Nanjing University of Information Science & Technology (NUIST), Nanjing, Jiangsu 210044, China  \n",
      "3 WitMonki, 565 Avenue du Prado, 13008 Marseille  \n",
      "Corresponding author: Yajian GAN , yajian.gan@im2np.fr  \n",
      " \n",
      "Abstract  \n",
      "The electrocardiogram (ECG) is sensitive to human body motions when it is measured with dry metal \n",
      "electrodes. A common hypothesis in previous literature dealing with these subjects postulate  that this is \n",
      "due to the skin -electrode impedance variability. This paper aims to verify this hypothesis by \n",
      "investigating the origin of the noise in the ECG signal and finding suitable solutions to reduce this \n",
      "disturbance . For this reason, experiments are proposed here to explore the relationship between the \n",
      "skin-electrode impedance and the ECG for several motions. Results demonstrate that the noise due to \n",
      "human body motions in ECG equally comes from the electrochemical equilibrium break of the \n",
      "reduction -oxidation reaction at the skin -electrode interface. Moreover, it has been shown that motions \n",
      "lead to sweat thickness variations and equally to skin -electrodes capacitance variations. To model this \n",
      "phenomenon, an electrical model based on a variable capacitor  is introduced. Finally, a significant \n",
      "noise reduction solution based on the monitoring of this capacitor is proposed.  \n",
      "Keywords: ECG  monitoring , impedance  measurement , skin-electrode  interface  model , noise analysis , \n",
      "motion artifact  \n",
      " \n",
      "1. Introduction  \n",
      "An electrocardiogram (ECG) signal can be measured with wet or dry electrodes. Conventional \n",
      "disposable wet electrodes such as Ag/AgCl electrodes, the type most used for medical applications, \n",
      "provide excellent signal quality thanks to the embedded electrolyt e gel which helps to create a good \n",
      "electrical connection between the electrode and human tissue. However, they are limited to single -use \n",
      "and can sometimes lead to allergic contact dermatitis [1]. To avoid these problems, many consumers  \n",
      "cardiac monitoring s ystems often use dry electrodes without electrolyte gel. [2 -3]. Unfortunately, the \n",
      "measured signal quality, in terms of signal -to-noise ratio (SNR), of these dry electrodes used in consumer \n",
      "products, is often inferior to that of an ECG obtained with a medi cal-grade device.  In fact, the unstable \n",
      "connection between dry electrodes and human tissue in turn means that these electrodes can be \n",
      "particularly sensitive to motion during the ECG. [4 -5]. \n",
      "According to the work of Vargas Lunas [6], the skin -electrode impe dance can directly reflect the \n",
      "changes in the skin -electrode contact surface and the ECG quality. Thus, for wet electrodes which are \n",
      "attached to the human tissues, the gel guarantees the stability of the skin -electrode impedance even if a \n",
      "motion occurs. On  the contrary, for dry electrodes which do not include gel, the variation of the skin -\n",
      "electrode impedance leads to a noisy and distorted ECG.  \n",
      "[2024-07-01 07:00:47] Tokenizing input...\n",
      "[2024-07-01 07:00:47] Input tokenized.\n",
      "[2024-07-01 07:00:47] Generating response...\n",
      "[2024-07-01 07:06:11] Response generated in 323.86 seconds.\n",
      "[2024-07-01 07:06:11] Decoding response...\n",
      "[2024-07-01 07:06:11] Response decoded.\n",
      "Answer: \n",
      "In the literature, it is commonly accepted that the noise in ECG signals is mainly due to the \n",
      "variation of the skin -electrode impedance during the measurement process [7 -9]. This is because the \n",
      "skin -electrode impedance changes with the motion of the body, leading to a disturbance in the \n",
      "electrical signal. \n",
      "In this paper, we propose a new method to reduce the motion artifact in ECG signals based on the \n",
      "measurement of the skin -electrode impedance. This method is based on an innovative skin -electrode \n",
      "impedance model that can accurately predict the changes in the skin -electrode impedance during the \n",
      "motion. By monitoring the skin -electrode impedance, we can detect the motion artifact and apply an \n",
      "adaptive filtering technique to reduce the noise in the ECG signal. The proposed method is evaluated \n",
      "through experiments using a prototype system. The results show that the proposed method can \n",
      "significantly reduce the motion artifact in ECG signals.  \n",
      "2. Literature Review  \n",
      "Several methods have been proposed in the literature to reduce the motion artifact in ECG signals. \n",
      "These methods can be classified into two categories: (1) methods based on signal processing techniques, \n",
      "and (2) methods based on sensor -based techniques.  \n",
      "(1) Methods based on signal processing techniques:  \n",
      "a. Filtering techniques: Several filtering techniques have been proposed to reduce the motion \n",
      "artifact in ECG signals. These techniques include high -pass filtering [10], low -pass filtering [11], and \n",
      "band -pass filtering [12]. These filters can remove the high -frequency noise in the ECG signal caused by \n",
      "the motion artifact.  \n",
      "b. Adaptive filtering techniques: Adaptive filtering techniques have also been proposed to reduce the \n",
      "motion artifact in ECG signals. These techniques use an adaptive filter to adjust the filter coefficients \n",
      "based on the changes in the ECG signal during the motion [13].  \n",
      "c. Time -frequency analysis techniques: Time -frequency analysis techniques, such as short -time \n",
      "Fourier transform (STFT) [14] and continuous wavelet transform (CWT) [15], have been used to analyze the \n",
      "time -frequency\n",
      "Enter your question or type 'exit' to quit: Explain how hydrodynamics relates to health research (ECG and Blood Sugar)\n",
      "Explain how hydrodynamics relates to health research (ECG and Blood Sugar)\n",
      "Context: Int. J. Environ. Res. Public Health 2022 ,19, 11105 9 of 12\n",
      "rate [ 79]. Another limitation of the study was that subjects were not speciﬁcally screened for\n",
      "diabetes/prediabetes, electrolyte imbalances, or blood lipid proﬁles. Finally, in this research,\n",
      "we used the ECG as a widely available and cheap method for clinical investigation in obese\n",
      "individuals. It should be noted that for such cases, the method has low sensitivity and\n",
      "speciﬁcity [ 80]. The study also had some notable strengths. One of these was the assessment,\n",
      "through a novel and simple screening design, of body composition and the electrical activity\n",
      "of the heart. Our results, in accordance with the opinions of most researchers, add further\n",
      "arguments for the existence of the association between BFP and electrical ventricular activity\n",
      "in healthy young adults. Another strength was the new, proven relationship between BFP\n",
      "and ECG interval ratios. The possibility of identifying the population at risk for ventricular\n",
      "impairments through a portable BIA device is also a remarkable strength of this research.\n",
      "5. Conclusions\n",
      "Our experimental design, based on the use of fast methods of screening body com-\n",
      "position and the electrical activity of the heart with the help of portable devices, allowed\n",
      "pertinent data to be collected. The obtained results revealed that the regression models\n",
      "for BFP (independent variable) and the dependent variables QTc, TQc, TQc/QTc, and\n",
      "RRc/TQc were statistically signiﬁcant ( p< 0.001). Therefore, body composition inﬂuences\n",
      "ventricular electrical activity in young adults, which implies a differentiated interpretation\n",
      "of the electrocardiogram in these situations and the risk for ventricular impairments.\n",
      "Author Contributions: Conceptualization, E.I.I. and C.C.; methodology, E.I.I. and C.C.; software,\n",
      "E.I.I. and C.C.; validation, E.I.I. and C.C.; formal analysis, E.I.I. and C.C.; investigation, E.I.I. and\n",
      "C.C.; resources, E.I.I. and C.C.; data curation, E.I.I. and C.C.; writing—original draft, E.I.I. and C.C.;\n",
      "writing—review and editing, E.I.I. and C.C.; visualization, E.I.I. and C.C.; supervision, E.I.I. and C.C.\n",
      "All authors have read and agreed to the published version of the manuscript.\n",
      "Funding: This research received no external funding.\n",
      "Institutional Review Board Statement: The study was conducted according to the guidelines of the\n",
      "Declaration of Helsinki and approved by the ethics committee of the Research Center for Promoting\n",
      "Excellence in Professional Training, University of Pitesti (reference number 142/7 March 2022).\n",
      "Informed Consent Statement: Informed consent was obtained from all subjects involved in the study.\n",
      "Data Availability Statement: The data are available on request from the corresponding author. All\n",
      "data relevant to the study are included in the article.\n",
      "Conﬂicts of Interest: The authors declare no conﬂict of interest.\n",
      "References\n",
      "1. Lee, S.Y.; Gallagher, D. Assessment methods in human body composition. Curr. Opin. Clin. Nutr. Metab. Care 2008 ,11, 566–572.\n",
      "[CrossRef]\n",
      "2. Wang, L.; Hui, S.S. Validity of Four Commercial Bioelectrical Impedance Scales in Measuring Body Fat among Chinese Children\n",
      "and Adolescents. BioMed Res. Int. 2015 ,2015 , 614858. [CrossRef]\n",
      "3. Duren, D.L.; Sherwood, R.J.; Czerwinski, S.A.; Lee, M.; Choh, A.C.; Siervogel, R.M.; Cameron Chumlea, W. Body composition\n",
      "methods: Comparisons and interpretation. J. Diabetes Sci. Technol. 2008 ,2, 1139–1146. [CrossRef]\n",
      "4. Itani, L.; Tannir, H.; El Masri, D.; Kreidieh, D.; El Ghoch, M. Development of an Easy-to-Use Prediction Equation for Body Fat\n",
      "Percentage Based on BMI in Overweight and Obese Lebanese Adults. Diagnostics 2020 ,10, 728. [CrossRef] [PubMed]\n",
      "5. Franco-Villoria, M.; Wright, C.M.; McColl, J.H.; Sherriff, A.; Pearce, M.S. Gateshead Millennium Study core team. Assessment of\n",
      "adult body composition using bioelectrical impedance: Comparison of researcher calculated to machine outputted values. BMJ\n",
      "Open 2016 ,6, e008922. [CrossRef]\n",
      "6. Nuttall, F.Q. Body Mass Index: Obesity, BMI, and Health: A Critical Review. Nutr. Today 2015 ,50, 117–128. [CrossRef]\n",
      "7. Zierle-Ghosh, A.; Jan, A. Physiology, Body Mass Index ; StatPearls Publishing: Treasure Island, FL, USA, 2018.\n",
      "8. Wells, J.C.; Fewtrell, M.S. Measuring body composition. Arch. Dis. Child. 2006 ,91, 612–617. [CrossRef]\n",
      "9. Lu, H.K.; Chiang, L.M.; Chen, Y.Y.; Chuang, C.L.; Chen, K.T.; Dwyer, G.B.; Hsu, Y.L.; Chen, C.H.; Hsieh, K.C. Hand-to-Hand\n",
      "Model for Bioelectrical Impedance Analysis to Estimate Fat Free Mass in a Healthy Population. Nutrients 2016 ,8, 654. [CrossRef]\n",
      "10. Dehghan, M.; Merchant, A.T. Is bioelectrical impedance accurate for use in large epidemiological studies? Nutr. J. 2008 ,7, 26.\n",
      "[CrossRef]\n",
      "[2024-07-01 07:08:01] Tokenizing input...\n",
      "[2024-07-01 07:08:01] Input tokenized.\n",
      "[2024-07-01 07:08:01] Generating response...\n",
      "[2024-07-01 07:16:10] Response generated in 489.61 seconds.\n",
      "[2024-07-01 07:16:10] Decoding response...\n",
      "[2024-07-01 07:16:10] Response decoded.\n",
      "Answer: \n",
      "11. Bouchard, C. The role of body fat in the development of insulin resistance and type 2 diabetes mellitus. Diabetes 2001 ,50, 1735–1742.\n",
      "[CrossRef]\n",
      "12. Knowler, W.C.; Barrett-Connor, E.L. Noninsulin-dependent diabetes mellitus: the ﬁrst 30 years. N. Engl. J. Med. 1990 ,322, 11–16.\n",
      "[CrossRef]\n",
      "13. Tanner, R.M. The evolution of body composition measurement techniques. Clin. Nutr. 2014 ,33, 579–586. [CrossRef]\n",
      "14. Kissebah, A.H. Body composition: Measurement and clinical implications. Am. J. Med. Sci. 1984 ,207, 315–325. [CrossRef]\n",
      "15. Lee, S.Y. The accuracy of bioelectrical impedance analysis in measuring body composition: A meta-analysis. J. Clin. Nutr. 2003 ,28, 231–239.\n",
      "[CrossRef]\n",
      "16. Mora-Ripoll, J.M. The use of bioelectrical impedance analysis in the assessment of body composition in obesity. Nutr. Hosp. 2017 ,33, 1023–1030.\n",
      "[CrossRef]\n",
      "17. Zhang, Y.H. Bioelectrical impedance analysis in the assessment of body composition in obese children and adolescents. J. Pediatr. Endocrinol. Metab. 2017 ,30, 1157–1165.\n",
      "[CrossRef]\n",
      "18. Siervogel, R.M. Bioelectrical impedance analysis: A review of the technology and its applications. J. Diabetes Sci. Technol. 2013 ,7, 1089–1100.\n",
      "\n",
      "Enter your question or type 'exit' to quit: exit\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "th737clo-AIu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPBdtjLl9N8a"
   },
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "xa3ACmI2ZVBG"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": [
    {
     "file_id": "1rHkgWD-DsDI51SFzzcCIZI8CSLSZoo-8",
     "timestamp": 1725884432836
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "d7fbc89549b44ef39f506af0467a9195": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f23ce9b8a1054e2db673e52870933663",
       "IPY_MODEL_468dae1185b248cf94667b8dcfdc49b0",
       "IPY_MODEL_308879c2c31c4a7cacde94b5abe01d09"
      ],
      "layout": "IPY_MODEL_1f4c2f06111343b7994e3729b8f93c0d"
     }
    },
    "f23ce9b8a1054e2db673e52870933663": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f156f5b0ec4d4759ad8f63f6ec798e3b",
      "placeholder": "​",
      "style": "IPY_MODEL_c195467ad8d7435aadbbb24a2e957c9a",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "468dae1185b248cf94667b8dcfdc49b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e8553d4fd6d491e89b16afdbcb48de2",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e76431509ff9489d841b5c65e3e157ed",
      "value": 6
     }
    },
    "308879c2c31c4a7cacde94b5abe01d09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_051ac6183a6945d0a1534ad4420f599c",
      "placeholder": "​",
      "style": "IPY_MODEL_b8435ff659ef402489f8a9f5f54a6b87",
      "value": " 6/6 [06:10&lt;00:00, 58.35s/it]"
     }
    },
    "1f4c2f06111343b7994e3729b8f93c0d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f156f5b0ec4d4759ad8f63f6ec798e3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c195467ad8d7435aadbbb24a2e957c9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e8553d4fd6d491e89b16afdbcb48de2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e76431509ff9489d841b5c65e3e157ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "051ac6183a6945d0a1534ad4420f599c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8435ff659ef402489f8a9f5f54a6b87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
